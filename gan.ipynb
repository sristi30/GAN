{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data [Only 4 moments]\n",
      "Epoch 0: D (0.7490968108177185 real_err, 0.6336177587509155 fake_err) G (0.755440354347229 err); Real Dist ([3.9484433910101653, 1.2284454920670274]),  Fake Dist ([0.24088232949376107, 0.0323644885174625]) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lenovo/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: D (0.5931983590126038 real_err, 0.6001887321472168 fake_err) G (0.7863580584526062 err); Real Dist ([3.9938577786684037, 1.2637233298612551]),  Fake Dist ([2.618754400730133, 0.010609699723107113]) \n",
      "Epoch 200: D (0.09719390422105789 real_err, 0.0855821892619133 fake_err) G (2.3968143463134766 err); Real Dist ([4.008558218002319, 1.1757513965077189]),  Fake Dist ([2.639625603199005, 0.15711760626053622]) \n",
      "Epoch 300: D (0.6912923455238342 real_err, 0.6717488169670105 fake_err) G (0.6876198649406433 err); Real Dist ([3.933358331859112, 1.26945794632914]),  Fake Dist ([2.4375218873023985, 2.3807680349121916]) \n",
      "Epoch 400: D (0.5653417110443115 real_err, 0.5355890393257141 fake_err) G (0.8795529007911682 err); Real Dist ([3.9578258094787597, 1.2492651479362125]),  Fake Dist ([4.979450378894806, 1.1132276342778082]) \n",
      "Epoch 500: D (0.5837213397026062 real_err, 0.511721670627594 fake_err) G (0.8411832451820374 err); Real Dist ([4.001049688503146, 1.2501995041518101]),  Fake Dist ([7.573856237888336, 2.41913825260033]) \n",
      "Epoch 600: D (0.7114503383636475 real_err, 0.716094970703125 fake_err) G (0.6712191700935364 err); Real Dist ([4.029738767027855, 1.2304408269923717]),  Fake Dist ([5.829490371704102, 1.8882811736998706]) \n",
      "Epoch 700: D (0.6981155276298523 real_err, 0.7007335424423218 fake_err) G (0.6856788992881775 err); Real Dist ([4.041359483122825, 1.2461794845665768]),  Fake Dist ([6.248614520549774, 1.9039220477625418]) \n",
      "Epoch 800: D (0.6959537267684937 real_err, 0.6975274682044983 fake_err) G (0.6887892484664917 err); Real Dist ([4.074367213487625, 1.2544690637150384]),  Fake Dist ([6.251761703968048, 1.8912417230057927]) \n",
      "Epoch 900: D (0.699004590511322 real_err, 0.6962755918502808 fake_err) G (0.6900125741958618 err); Real Dist ([3.9385387080907823, 1.2158186523676873]),  Fake Dist ([6.224606880187988, 1.9686665906108285]) \n",
      "Epoch 1000: D (0.6954959034919739 real_err, 0.6956143975257874 fake_err) G (0.6906942129135132 err); Real Dist ([4.00837104433775, 1.269327453670096]),  Fake Dist ([6.335952191829682, 1.8859838047649486]) \n",
      "Epoch 1100: D (0.694794237613678 real_err, 0.6950096487998962 fake_err) G (0.6912986636161804 err); Real Dist ([4.016373484134674, 1.198472646609483]),  Fake Dist ([6.403181707859039, 1.9533091467964727]) \n",
      "Epoch 1200: D (0.6947827935218811 real_err, 0.6946088075637817 fake_err) G (0.6916977167129517 err); Real Dist ([4.003703040122986, 1.2387869335077595]),  Fake Dist ([6.2365368411540985, 1.8536388745270562]) \n",
      "Epoch 1300: D (0.6944698095321655 real_err, 0.6943655014038086 fake_err) G (0.6919329166412354 err); Real Dist ([4.067768326997757, 1.248841110752296]),  Fake Dist ([6.363255242824555, 1.971960058907617]) \n",
      "Epoch 1400: D (0.6945610642433167 real_err, 0.6941567063331604 fake_err) G (0.6921367049217224 err); Real Dist ([4.005949781753123, 1.2841465989268697]),  Fake Dist ([6.342169873714447, 1.9274373116003998]) \n",
      "Epoch 1500: D (0.6945711970329285 real_err, 0.6938471794128418 fake_err) G (0.6924428939819336 err); Real Dist ([4.054254398822785, 1.2474059992263593]),  Fake Dist ([6.256861337661743, 1.892475427876579]) \n",
      "Epoch 1600: D (0.694036602973938 real_err, 0.6935957670211792 fake_err) G (0.6927034854888916 err); Real Dist ([4.0655784038305285, 1.242260995073596]),  Fake Dist ([6.42143935585022, 1.9088563137782655]) \n",
      "Epoch 1700: D (0.694017231464386 real_err, 0.6931087970733643 fake_err) G (0.693191647529602 err); Real Dist ([4.095206697463989, 1.2381803893823211]),  Fake Dist ([6.523113281726837, 1.970639007124207]) \n",
      "Epoch 1800: D (0.6939386129379272 real_err, 0.6919876933097839 fake_err) G (0.6943073272705078 err); Real Dist ([4.048933389604092, 1.3049996073348558]),  Fake Dist ([6.199009285926818, 1.9039239416647185]) \n",
      "Epoch 1900: D (0.6770846843719482 real_err, 0.6685394048690796 fake_err) G (0.7183841466903687 err); Real Dist ([4.027022648990155, 1.2490591136994498]),  Fake Dist ([6.3424578137397765, 1.9302578414524818]) \n",
      "Epoch 2000: D (0.7009195685386658 real_err, 0.7165767550468445 fake_err) G (0.6674516201019287 err); Real Dist ([4.032403138279915, 1.2280746001540086]),  Fake Dist ([4.784255807876587, 0.7678453807526585]) \n",
      "Epoch 2100: D (0.6950793266296387 real_err, 0.6952940821647644 fake_err) G (0.6909886002540588 err); Real Dist ([3.9343993138074875, 1.245225223604538]),  Fake Dist ([5.2930510730743405, 0.9534628741565537]) \n",
      "Epoch 2200: D (0.6953402161598206 real_err, 0.6944805979728699 fake_err) G (0.6917757987976074 err); Real Dist ([3.8649442340135574, 1.2598920365116058]),  Fake Dist ([5.473389015197754, 0.969338866128073]) \n",
      "Epoch 2300: D (0.6943175792694092 real_err, 0.6942352056503296 fake_err) G (0.6920676231384277 err); Real Dist ([3.9565739245414733, 1.2225583550387684]),  Fake Dist ([5.4951551761627195, 0.9368216261984886]) \n",
      "Epoch 2400: D (0.6940442323684692 real_err, 0.6940683722496033 fake_err) G (0.6922488808631897 err); Real Dist ([4.003042936444283, 1.2195565752850597]),  Fake Dist ([5.653267384529114, 0.9943590250275118]) \n",
      "Epoch 2500: D (0.6934661269187927 real_err, 0.6940282583236694 fake_err) G (0.6922851800918579 err); Real Dist ([4.149040270403027, 1.2344624166375975]),  Fake Dist ([5.682509839057922, 0.9783267765135583]) \n",
      "Epoch 2600: D (0.6937201619148254 real_err, 0.6939297318458557 fake_err) G (0.692382276058197 err); Real Dist ([4.007553913354874, 1.2876684061924082]),  Fake Dist ([5.779840742111206, 0.9910230414325398]) \n",
      "Epoch 2700: D (0.6937316060066223 real_err, 0.6938751935958862 fake_err) G (0.6923932433128357 err); Real Dist ([4.052294478297234, 1.2244017266769123]),  Fake Dist ([5.833883242607117, 1.0175365992570258]) \n",
      "Epoch 2800: D (0.6934378147125244 real_err, 0.6938434839248657 fake_err) G (0.6924402713775635 err); Real Dist ([4.101609398543835, 1.266370161885856]),  Fake Dist ([5.828457912445068, 0.989745061422825]) \n",
      "Epoch 2900: D (0.6937571167945862 real_err, 0.693795382976532 fake_err) G (0.6924693584442139 err); Real Dist ([4.020428918421269, 1.2515356643612778]),  Fake Dist ([5.873604739189148, 1.0033352876696702]) \n",
      "Epoch 3000: D (0.693735659122467 real_err, 0.6938037872314453 fake_err) G (0.6924946308135986 err); Real Dist ([4.030728615403175, 1.2162326698909565]),  Fake Dist ([5.867367883682251, 0.9485372511430472]) \n",
      "Epoch 3100: D (0.6936729550361633 real_err, 0.6937161087989807 fake_err) G (0.6925675272941589 err); Real Dist ([4.035835466980934, 1.308768478062857]),  Fake Dist ([5.985538842201233, 0.977944164063369]) \n",
      "Epoch 3200: D (0.6934804320335388 real_err, 0.6937244534492493 fake_err) G (0.6925720572471619 err); Real Dist ([4.1250038337707515, 1.2288708580483676]),  Fake Dist ([5.917556831359863, 0.9517497812360329]) \n",
      "Epoch 3300: D (0.693670928478241 real_err, 0.6937204003334045 fake_err) G (0.692561686038971 err); Real Dist ([3.979099616527557, 1.249733758020463]),  Fake Dist ([5.897954606056214, 0.9675229259561243]) \n",
      "Epoch 3400: D (0.6934892535209656 real_err, 0.6936898231506348 fake_err) G (0.6926136016845703 err); Real Dist ([4.141444790482521, 1.225298292826072]),  Fake Dist ([5.964642254829407, 0.9801931876625375]) \n",
      "Epoch 3500: D (0.6936466693878174 real_err, 0.6936159133911133 fake_err) G (0.6926652193069458 err); Real Dist ([3.974033920288086, 1.179283430257994]),  Fake Dist ([5.954772565841675, 0.9577601399042327]) \n",
      "Epoch 3600: D (0.6934884190559387 real_err, 0.6936062574386597 fake_err) G (0.6926889419555664 err); Real Dist ([3.999484623968601, 1.317303544190068]),  Fake Dist ([6.008738418579101, 1.00405214228627]) \n",
      "Epoch 3700: D (0.6939666867256165 real_err, 0.6936476230621338 fake_err) G (0.6926521062850952 err); Real Dist ([3.9534836161136626, 1.1822227171446544]),  Fake Dist ([5.967198930740357, 0.9439729647105694]) \n",
      "Epoch 3800: D (0.6936658024787903 real_err, 0.6935902833938599 fake_err) G (0.6927007436752319 err); Real Dist ([4.021323238119483, 1.2502923337756215]),  Fake Dist ([6.0556721534729006, 0.9567243480494549]) \n",
      "Epoch 3900: D (0.6938929557800293 real_err, 0.6935762166976929 fake_err) G (0.6927163600921631 err); Real Dist ([4.005237773776054, 1.2158997990017384]),  Fake Dist ([6.042222602844238, 0.9718269449180501]) \n",
      "Epoch 4000: D (0.6935214400291443 real_err, 0.6935264468193054 fake_err) G (0.6927699446678162 err); Real Dist ([4.082957174837589, 1.2308879778595845]),  Fake Dist ([5.940333422660828, 0.9108216481180178]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4100: D (0.6936395168304443 real_err, 0.6935544610023499 fake_err) G (0.6927390694618225 err); Real Dist ([4.015488250613212, 1.2243727644920053]),  Fake Dist ([6.03962288570404, 0.9538384339610768]) \n",
      "Epoch 4200: D (0.6935240626335144 real_err, 0.693510115146637 fake_err) G (0.6927778124809265 err); Real Dist ([4.010637751251459, 1.2143319778666448]),  Fake Dist ([6.036418906211853, 0.9563626056759795]) \n",
      "Epoch 4300: D (0.6934940218925476 real_err, 0.693498432636261 fake_err) G (0.692797839641571 err); Real Dist ([3.9788567459136246, 1.2578792304236095]),  Fake Dist ([6.107941230773926, 0.9792848858257838]) \n",
      "Epoch 4400: D (0.693483293056488 real_err, 0.693519651889801 fake_err) G (0.6927815079689026 err); Real Dist ([3.9724618227481843, 1.2342788706227792]),  Fake Dist ([6.130647192001343, 0.9416580341810611]) \n",
      "Epoch 4500: D (0.6933583617210388 real_err, 0.6934831738471985 fake_err) G (0.6928145289421082 err); Real Dist ([4.032872279405594, 1.198758559707202]),  Fake Dist ([6.09849896812439, 0.9684915619131628]) \n",
      "Epoch 4600: D (0.6934763789176941 real_err, 0.6934531331062317 fake_err) G (0.6928340792655945 err); Real Dist ([3.985830136477947, 1.2216940814917032]),  Fake Dist ([6.138219648361206, 1.0128726090354934]) \n",
      "Epoch 4700: D (0.6937093734741211 real_err, 0.6934707760810852 fake_err) G (0.6928163170814514 err); Real Dist ([3.9249134491682054, 1.2676126380797206]),  Fake Dist ([6.167981475830078, 1.0002164023512918]) \n",
      "Epoch 4800: D (0.6934959292411804 real_err, 0.693461000919342 fake_err) G (0.6928392052650452 err); Real Dist ([4.037188592433929, 1.1513072486471185]),  Fake Dist ([6.064340779304504, 0.9639541324654526]) \n",
      "Epoch 4900: D (0.6934401988983154 real_err, 0.6934406161308289 fake_err) G (0.6928583979606628 err); Real Dist ([3.9967132326364516, 1.2734978611688803]),  Fake Dist ([6.160091083526611, 0.9669754182742453]) \n",
      "Plotting the generated distribution...\n",
      " Values: [5.4507904052734375, 8.038764953613281, 5.257846832275391, 6.516222953796387, 6.211223602294922, 5.563497066497803, 5.864318370819092, 7.481905937194824, 5.6901164054870605, 5.56380033493042, 5.706007480621338, 5.265383243560791, 6.090900897979736, 5.310900688171387, 5.028148651123047, 7.9568986892700195, 7.996020793914795, 5.582552433013916, 5.667760372161865, 5.51032018661499, 5.515021324157715, 5.258892059326172, 5.56031608581543, 5.79678201675415, 5.598822116851807, 5.55129337310791, 7.342695236206055, 5.922727584838867, 5.8918375968933105, 5.296344757080078, 5.714839458465576, 5.650858402252197, 5.411327838897705, 5.297203540802002, 5.116814613342285, 8.040406227111816, 5.430432319641113, 5.466644287109375, 5.35987663269043, 5.195814609527588, 5.433306694030762, 5.935211181640625, 7.996385097503662, 6.107850551605225, 6.820530891418457, 5.025949954986572, 5.754748821258545, 5.313597202301025, 5.890835285186768, 7.617103099822998, 6.641829967498779, 5.496514320373535, 5.59129524230957, 5.06201171875, 5.163067817687988, 5.560262203216553, 5.903726100921631, 6.0655412673950195, 5.606761455535889, 5.619148254394531, 6.156536102294922, 5.382079601287842, 6.893742084503174, 5.403529644012451, 6.795288562774658, 5.22754430770874, 5.719125270843506, 7.616343975067139, 6.090954303741455, 5.262055397033691, 4.83302116394043, 7.187334060668945, 6.454903602600098, 6.230495929718018, 7.503276348114014, 6.560308933258057, 8.078707695007324, 5.545547008514404, 5.324265956878662, 5.808534622192383, 5.491479396820068, 7.86326789855957, 5.900661945343018, 6.6192851066589355, 7.208035945892334, 5.437634468078613, 6.0031208992004395, 5.4051079750061035, 7.134209632873535, 5.0858235359191895, 8.031146049499512, 7.6406402587890625, 5.026198863983154, 8.046154022216797, 5.2904767990112305, 4.8352580070495605, 5.854851722717285, 7.703006744384766, 7.564382076263428, 5.610744953155518, 6.037101745605469, 5.237661361694336, 5.714428424835205, 5.568456172943115, 6.988243579864502, 7.750033378601074, 5.551878452301025, 6.809879302978516, 5.415999412536621, 5.695436000823975, 5.399947643280029, 6.111166000366211, 7.1768293380737305, 6.7164225578308105, 6.0716400146484375, 5.385617733001709, 7.339945316314697, 5.636199474334717, 5.4496564865112305, 5.7009453773498535, 5.605531215667725, 5.497663497924805, 5.480501174926758, 8.03076457977295, 7.959509372711182, 5.477543830871582, 5.509634017944336, 5.129057884216309, 5.428680419921875, 5.0494866371154785, 5.2283501625061035, 5.817185878753662, 5.1797261238098145, 6.175477027893066, 7.624706268310547, 7.9126667976379395, 7.828418254852295, 7.730332851409912, 7.721452236175537, 5.538049697875977, 7.833256721496582, 8.076882362365723, 5.4794416427612305, 5.590779781341553, 5.3882856369018555, 5.8387370109558105, 4.725769996643066, 6.158822059631348, 7.756540775299072, 6.904924392700195, 5.5768723487854, 8.016353607177734, 5.572456359863281, 5.926558017730713, 5.600604057312012, 5.2056989669799805, 8.04984188079834, 5.481762886047363, 5.86873197555542, 5.107692718505859, 5.48427677154541, 6.260581016540527, 5.419129848480225, 5.871878147125244, 5.8871169090271, 5.57906436920166, 5.570333957672119, 7.751006126403809, 5.416663646697998, 7.978865146636963, 5.387848854064941, 5.524735927581787, 5.534287452697754, 5.771005630493164, 5.354362964630127, 7.950473785400391, 5.466881275177002, 6.410390853881836, 6.059422016143799, 5.6224284172058105, 5.482030391693115, 5.192502498626709, 8.077513694763184, 6.362841606140137, 7.038710117340088, 5.4974541664123535, 5.485344886779785, 5.655778884887695, 7.275672435760498, 5.707706928253174, 5.499543190002441, 7.397858142852783, 5.995690822601318, 5.66798210144043, 4.786224365234375, 4.987420082092285, 5.38784646987915, 5.470499038696289, 7.378203868865967, 5.275707721710205, 5.794164180755615, 7.961122989654541, 5.707798004150391, 7.945466041564941, 5.5747809410095215, 5.097769260406494, 7.790471076965332, 7.330879211425781, 7.911623477935791, 8.075075149536133, 5.573853015899658, 5.4503045082092285, 5.019360065460205, 4.7243571281433105, 5.594525337219238, 5.367284297943115, 6.090174674987793, 5.151893615722656, 7.798402309417725, 5.401735782623291, 7.721959590911865, 6.61651086807251, 5.300506591796875, 6.51609992980957, 5.29328727722168, 5.596504211425781, 6.677245140075684, 5.466436386108398, 5.5095367431640625, 5.147910118103027, 5.312789440155029, 6.33071231842041, 7.502697944641113, 5.7255096435546875, 5.723838806152344, 7.023018836975098, 5.608312606811523, 4.73551607131958, 6.745555400848389, 5.548952102661133, 5.684566974639893, 8.071022033691406, 6.539857864379883, 6.3325724601745605, 7.749998569488525, 5.5822062492370605, 6.299143314361572, 8.067117691040039, 6.907795429229736, 5.474373817443848, 5.79111385345459, 7.9679083824157715, 5.48577880859375, 5.808201313018799, 4.895975589752197, 5.4220452308654785, 6.826043128967285, 7.603482246398926, 6.009639263153076, 6.154914855957031, 5.093455791473389, 7.150115013122559, 5.792129993438721, 5.877687931060791, 7.248798847198486, 8.052042007446289, 7.5628132820129395, 5.652166366577148, 8.001880645751953, 6.439472198486328, 5.608309268951416, 5.48577880859375, 7.026692867279053, 5.6254048347473145, 7.588959217071533, 7.842508792877197, 4.787621974945068, 7.1334710121154785, 5.44474983215332, 5.790013313293457, 5.0021748542785645, 6.221117973327637, 7.876183986663818, 8.047995567321777, 7.9891743659973145, 8.07197380065918, 6.757297515869141, 7.131991386413574, 5.697774410247803, 4.75912618637085, 5.764533519744873, 4.843698501586914, 5.479943752288818, 5.527190685272217, 5.500514984130859, 8.023883819580078, 6.049416542053223, 5.544894218444824, 5.681262493133545, 5.993229389190674, 4.860667705535889, 8.0757417678833, 5.580512523651123, 7.030979633331299, 5.423447608947754, 7.317395210266113, 6.74779748916626, 8.030734062194824, 5.806422710418701, 5.845693111419678, 5.388206481933594, 5.242074966430664, 7.814913272857666, 6.797452449798584, 5.523098468780518, 5.745781898498535, 5.300558090209961, 5.718617916107178, 6.142975330352783, 7.659270763397217, 6.2926025390625, 5.122310638427734, 5.5072407722473145, 6.5085368156433105, 6.325075149536133, 5.542818069458008, 6.403130054473877, 5.2559661865234375, 7.725614547729492, 5.102227687835693, 5.763277530670166, 5.4761433601379395, 7.497302532196045, 8.006321907043457, 5.275484085083008, 5.93922758102417, 5.424126148223877, 6.760035991668701, 6.329523086547852, 5.975358963012695, 4.73313045501709, 4.985713958740234, 7.249021053314209, 5.583031177520752, 5.567339897155762, 4.960956573486328, 7.589308738708496, 8.052555084228516, 5.893700122833252, 5.459177017211914, 5.6730875968933105, 5.72393274307251, 5.406928062438965, 5.8074116706848145, 5.54937744140625, 5.623178958892822, 5.384085178375244, 5.591068744659424, 5.799407482147217, 6.398289203643799, 5.626265048980713, 5.541821002960205, 5.875864505767822, 5.423648834228516, 5.2578887939453125, 5.1612629890441895, 5.860013484954834, 8.077201843261719, 5.789012432098389, 5.217953205108643, 5.4027838706970215, 7.486983299255371, 7.407246112823486, 5.467617988586426, 7.257153034210205, 5.56582498550415, 5.675901412963867, 5.011521339416504, 6.692325115203857, 6.0694756507873535, 7.38189697265625, 5.465930461883545, 7.704184055328369, 8.064447402954102, 5.224730491638184, 7.542325496673584, 5.440901279449463, 6.55178689956665, 5.175121784210205, 5.366166591644287, 5.566353797912598, 5.626309394836426, 6.208372592926025, 6.904269695281982, 6.329049110412598, 8.010830879211426, 6.292212009429932, 6.481303691864014, 6.219386100769043, 5.238644599914551, 7.908607006072998, 7.995687007904053, 7.501967906951904, 5.973171234130859, 4.855983734130859, 4.931398391723633, 7.82603120803833, 7.993849754333496, 6.439289569854736, 5.378258228302002, 5.37287712097168, 7.939024448394775, 8.066468238830566, 7.809268474578857, 5.169629096984863, 7.631919860839844, 6.327617645263672, 5.687015533447266, 5.551074504852295, 5.1821393966674805, 5.2830023765563965, 6.241273880004883, 5.455659866333008, 5.616007328033447, 7.238933086395264, 8.070911407470703, 6.094618320465088, 5.959515571594238, 5.111209869384766, 5.347516059875488, 6.173357009887695, 5.417110443115234, 8.033967971801758, 5.84254789352417, 7.993155002593994, 5.564528942108154, 4.945342540740967, 5.504395008087158, 5.507870674133301, 5.570554256439209, 5.962932586669922, 7.619542598724365, 5.640214920043945, 7.6145734786987305, 5.116263389587402, 5.722670555114746, 6.212766170501709, 5.5949554443359375, 5.621910572052002, 5.2254109382629395, 5.4456787109375, 5.8279643058776855, 7.9723639488220215, 6.54280424118042, 7.023775100708008, 5.473865985870361, 7.889679908752441, 7.156243324279785, 5.692581653594971, 6.264773368835449, 5.880265712738037, 5.160059452056885, 6.084516525268555, 7.92124605178833, 5.092133045196533, 5.59002161026001, 7.915783882141113, 7.577463626861572, 5.703182697296143, 7.9240288734436035, 5.87078857421875, 5.03590202331543, 5.555508613586426, 6.092949390411377, 5.606249809265137, 5.53097677230835, 5.5268874168396, 5.625629425048828, 5.94767951965332, 5.114292621612549, 5.915122032165527, 5.6310224533081055, 6.612406253814697, 4.868375778198242, 5.466686248779297, 4.850460529327393, 5.917872905731201, 5.405269145965576, 5.597842693328857, 6.053426265716553, 7.25504207611084, 7.70528507232666, 5.1289167404174805, 8.035615921020508, 5.365677356719971, 4.965882301330566, 5.583252429962158, 7.604629039764404, 6.294193744659424, 7.875913143157959]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHxZJREFUeJzt3XuYXHWd5/H3x0AgpiFRiWUISFAYd5SMaFoG1HG7QWYQdZBdZgcGkXiLjiOPl8jKuDrCeMNnuK06o0ZxQGVomAw3ERAWaFhmBe1gpIngA0ICSSCRW6AhKg3f/eP8OqmuVHVVdfepS87n9Tz1dNW5fvpXl2+dc351jiICMzMrrhe0O4CZmbWXC4GZWcG5EJiZFZwLgZlZwbkQmJkVnAuBmVnBuRB0GUmrJfW1O0c7STpa0oOSRiS9rt152k3SqZJ+OMVljEh6xTTl+Yyk76b7CyWFpJ2madkvT1lnTMfyLONC0EEkrZH01ophSyTdMvY4Il4TEYN1ljOtb74OdAbw0YjoiYhfVI5U5qOS7pD0jKSHJQ1KOrYNWeuq9rxP47L7JD2fPjxHJK2TdLGkN5RPl9ryvgaWta7eOiPiyxHxgalmT+sc1zYR8UDK+tx0LN8yLgTWtA4oMPsAqycY/zXg48Ay4CXAAuCzwBH5RxuvA9oKYENE9AC7AQcDdwP/V9Jh072iDvl/rVkR4VuH3IA1wFsrhi0Bbqk2DXAQMAQ8CWwEzkrDHwACGEm3Q8iK/meBtcAm4PvAnLLlvieNexT4XMV6TgVWAD9M6/pAWvdPgSeAh4BvADPLlhfAR4B7gKeALwCvTPM8CVxcPn3F/1w1K7BL+n8CeBr4TZV5/wh4Duit09ZzgHNT9vXAF4EZ5W1OtuXxOHA/8LYm5v1P4GzgsTTulcANqW0fAS4A5qbpfwA8D2xJ/9v/TMMPBv5fat9fAn1l698XuCm163Wp7X9Y4//sA9ZVGf4NYKji+dov3T8S+FVa/nrgU8DslPF5tr2u9qzx2jh1LA+wMC17KbAhtdmysvWeB3yxWt5qbVO2vJ3SNHsCV6S2vhf4YNmyTiV7nX0//S+r670uinprewDfyp6M5gvBT4ET0v0e4OB0f9ybJQ17X3qjvCJNewnwgzTu1emN9mZgJtkH4LOMLwTPAu8i+5CeBSwm+7DaKa3vLuDjZeuL9AbdHXgN8Hvg+rT+OemD5sQa7VAza9my96sx74eBNQ209WXAt8k+4F4K/Az4UFmbPwt8EJgB/G36EFOD844CJ6W2mQXsBxxOVsjmATcD59R63sm2YB4l+0B+QZr3UWBe2fN+VlreW8g+5JotBIeSfcjOrmxTsg/rP0v3XwS8vtayarw2TmX7QnBhaq9FwG/Z9to6jxqFoEbbjC1vrBDcBPwLsCtwYFr2YWXZfpfacQbwFeDWdr/PO/HmXUOd5zJJT4zdyF7ktTwL7Cdpj4gYiYhbJ5j2eLIthvsiYgT4e+DYtCl/DPCjiLglIv4A/APZm63cTyPisoh4PiK2RMTKiLg1IkYjYg3ZB+N/rZjnqxHxZESsBu4Erk3r3wxcDdQ60DtR1nr2AB4uH5D2iz8h6XeS9pFUAt5GVriejohNZN/gy48hrI2I70S2L/p8YD5QanDeDRHx9dQ2WyLi3oi4LiJ+HxG/JfsQr2yrcu8GroqIq1J7X0e25XekpJcDbwA+l5Z3M/CjBtql0gZAwNwq454FXi1p94h4PCJur7Osca+NGtOcltprGPhX4LhJZB5H0t5kX14+HRG/i4hVwHeBE8omuyW143NkWxivnep6d0QuBJ3nXRExd+xGtnullveT7Qq5W9LPJb1jgmn3JNvVMmYt2TfWUhr34NiIiHiG7BtouQfLH0j6I0lXpgOxTwJfJvsQLrex7P6WKo97JpG1nkfJPrS3ioi9UrZdyD789gF2Bh4qK7jfJvt2P+bhsvmfSXd7Gpy3sq1eKmlA0vrUVj9k+7Yqtw/wVxVfCN6c/q89gccj4umy6ddWW0gdC8iK/RNVxv13sm/RayXdJOmQOst6sM74ymnWkv0fU7Un8FhEPFWx7AVlj8u/FDwD7OrjGNtzIehiEXFPRBxH9iH0VWCFpNls/20esm+A+5Q9fjnZLoyNZLsC9hobIWkW2UHWcaurePxNsoOO+0fE7sBnyD5kp8NEWeu5AdhLUu8E0zxItqtqj7Kiu3tEvKaB5Tcyb2VbfSUN+5PUVu9mfFtVTv8g2a6wuWW32RFxOtlz9aL0PI95eQO5Kx0N3F5RULIwET+PiKPIXleXke1nr5azVv5q9i67/3Ky5xiyYz0vLBv3siaWvQF4saTdKpa9voE8VsaFoItJerekeRHxPNu+2T1Htp/0ebJ97GMuBD4haV9JPWTf4C+KiFGyg33vlPRGSTOB06j/ob4b2cHBEUn/hWw/+nSZKOuEIuLXZN/QByQdLmlW6nP+xrJpHgKuBc6UtLukF0h6paSJdtdMZd7dyI7BPCFpAXByxfiNjH+ufkj2fPyFpBmSdk1dN/eKiLVku4lOkzRT0puBd9bLDVu71S6Q9Hmyg7qfqTLNTEnHS5oTEc+SPcdjXTU3Ai+RNKeR9VX4nKQXSnoN8F7gojR8FdkurxdLehlZb69ylW2zVUQ8SHZA/Supjf6EbCv5gknkKzQXgu52BLBa0gjwv4Fj077SZ4AvAf+Zdi0cDHyPbB/pzWS9YH5HdkCTtA//JGCA7BvnU2S9dX4/wbo/BfxNmvY7bHtjT4eaWRv0d2RdSM8i602yjqzX0l+T9aiCrJfUTLKD1o+TFcP52y2pumbnPQ14PbAZ+DHZwe9yXwE+m56rT6UPuKPIPqh/S7aFcDLb3q9/A/xp+t8+T9YrZiJ7ptfICPBzsgO2fRFxbY3pTwDWpN1YHybbgiEi7iYr0velrM3s3rmJrAPA9cAZZev+AVmvqDVkBbbydTSubaos9ziyA8gbgEuBz6djKtaEsV4QZlulb+FPkO32ub/decwsX94iMAAkvTNtus8m6z46TPYtzcx2cC4ENuYoss3rDcD+ZLuZvLloVgDeNWRmVnDeIjAzK7iu+GHFHnvsEQsXLmx3jJqefvppZs+eXX/CDtONuZ25dboxtzOPt3LlykciYl696bqiECxcuJChoaF2x6hpcHCQvr6+dsdoWjfmdubW6cbczjyepIZ+de5dQ2ZmBedCYGZWcC4EZmYF50JgZlZwLgRmZgXnQmBmVnC5F4J0Gt1fSLoyPd5X0m2S7pF0UTrtsZmZtUkrtgg+RnY92zFfBc6OiP3JTuH7/hZkMDOzGnItBJL2At5Odh1RJInsotkr0iTnk1302szM2iTXk85JWkF2YYndyC5ksgS4NSL2S+P3Bq6OiAOqzLsUWApQKpUWDwwM5JZzqkZGRujpqXX53c41lnt4/eaq4xctmMyFqPLVjW3djZmhO3M783j9/f0rI2Kiy7YCOZ5iIl1IfVNErJTUNza4yqRVK1FELAeWA/T29kYn/2y8G3/WDttyLznlx1XHrzm+r7WBGtCNbd2NmaE7czvz5OR5rqE3AX8p6UhgV2B34BxgrqSd0vVn92LbRazNzKwNcjtGEBF/HxF7RcRC4Fjghog4HrgROCZNdiJweV4ZzMysvnb8juDTwCcl3Qu8BDi3DRnMzCxpyWmoI2IQGEz37wMOasV6zcysPv+y2Mys4FwIzMwKzoXAzKzgXAjMzArOhcDMrOBcCMzMCs6FwMys4FwIzMwKzoXAzKzgWvLLYusMCyvOMrps0WjNM4+aWXF4i8DMrOBcCMzMCs6FwMys4FwIzMwKzoXAzKzgXAjMzAout0IgaVdJP5P0S0mrJZ2Whp8n6X5Jq9LtwLwymJlZfXn+juD3wKERMSJpZ+AWSVencSdHxIoc121mZg3KrRBERAAj6eHO6RZ5rc/MzCYn12MEkmZIWgVsAq6LiNvSqC9JukPS2ZJ2yTODmZlNTNkX95xXIs0FLgVOAh4FHgZmAsuB30TEP1aZZymwFKBUKi0eGBjIPedkjYyM0NPT0+4YdQ2v3zzucWkWbNxSe/pFC+bknKh53dLW5boxM3Rnbmcer7+/f2VE9NabriWFAEDS54GnI+KMsmF9wKci4h0Tzdvb2xtDQ0M5J5y8wcFB+vr62h2jrmrnGjpzuPbewTWnvz3vSE3rlrYu142ZoTtzO/N4khoqBHn2GpqXtgSQNAt4K3C3pPlpmIB3AXfmlcHMzOrLs9fQfOB8STPICs7FEXGlpBskzQMErAI+nGMGMzOrI89eQ3cAr6sy/NC81mlmZs3zL4vNzArOhcDMrOBcCMzMCs6FwMys4FwIzMwKzoXAzKzgXAjMzArOhcDMrOBcCMzMCs6FwMys4FwIzMwKzoXAzKzgXAjMzArOhcDMrOBcCMzMCs6FwMys4FwIzMwKLs9rFu8q6WeSfilptaTT0vB9Jd0m6R5JF0mamVcGMzOrL88tgt8Dh0bEa4EDgSMkHQx8FTg7IvYHHgfen2MGMzOrI7dCEJmR9HDndAvgUGBFGn4+8K68MpiZWX2KiPwWLs0AVgL7Af8M/BNwa0Tsl8bvDVwdEQdUmXcpsBSgVCotHhgYyC3nVI2MjNDT09PuGHUNr9887nFpFmzcUnv6RQvm5Jyoed3S1uW6MTN0Z25nHq+/v39lRPTWm26nXNaeRMRzwIGS5gKXAn9cbbIa8y4HlgP09vZGX19fXjGnbHBwkE7ON2bJKT8e93jZolHOHK79ElhzfF/OiZrXLW1drhszQ3fmdubJaUmvoYh4AhgEDgbmShr79NkL2NCKDGZmVl2evYbmpS0BJM0C3grcBdwIHJMmOxG4PK8MZmZWX567huYD56fjBC8ALo6IKyX9ChiQ9EXgF8C5OWYwM7M6cisEEXEH8Loqw+8DDsprvWZm1hz/stjMrOBcCMzMCs6FwMys4FwIzMwKzoXAzKzgcv1lsbXHwopfEJuZTcRbBGZmBedCYGZWcC4EZmYF50JgZlZwLgRmZgXnQmBmVnAuBGZmBedCYGZWcC4EZmYF518Wm5m12URnA1hz+ttzX7+3CMzMCi7PaxbvLelGSXdJWi3pY2n4qZLWS1qVbkfmlcHMzOrLc9fQKLAsIm6XtBuwUtJ1adzZEXFGjus2M7MG5XnN4oeAh9L9pyTdBSzIa31mZjY5ioj8VyItBG4GDgA+CSwBngSGyLYaHq8yz1JgKUCpVFo8MDCQe87JGhkZoaenp90xthpev7mh6UqzYOOW5pe/aMGc5meaJp3W1o3oxszQnbm7NfP9m5+rOX4q77f+/v6VEdFbb7rcC4GkHuAm4EsRcYmkEvAIEMAXgPkR8b6JltHb2xtDQ0O55pyKwcFB+vr62h1jq0avR7Bs0ShnDje/UdiKXgy1dFpbN6IbM0N35u7WzEuuebrm+Km83yQ1VAhy7TUkaWfgP4ALIuISgIjYGBHPRcTzwHeAg/LMYGZmE8uz15CAc4G7IuKssuHzyyY7GrgzrwxmZlZfnr2G3gScAAxLWpWGfQY4TtKBZLuG1gAfyjGDmZnVkWevoVsAVRl1VV7rNDOz5vkUE9a0Wgej23kQ2cwmz6eYMDMrOBcCM7OCa6gQSHpTI8PMzKz7NLpF8PUGh5mZWZeZ8GCxpEOANwLzJH2ybNTuwIw8g5mZWWvU6zU0E+hJ0+1WNvxJ4Ji8QpmZWetMWAgi4ibgJknnRcTaFmUyM7MWavR3BLtIWg4sLJ8nIg7NI5SZmbVOo4Xg34FvAd8Fap8v1czMuk6jhWA0Ir6ZaxIzM2uLRruP/kjSRyTNl/TisVuuyczMrCUa3SI4Mf09uWxYAK+Y3jhmZtZqDRWCiNg37yBmZtYeDRUCSe+pNjwivj+9cczMrNUa3TX0hrL7uwKHAbcDLgRmZl2u0V1DJ5U/ljQH+EEuiczMrKUmexrqZ4D9J5pA0t6SbpR0l6TVkj6Whr9Y0nWS7kl/XzTJDGZmNg0aPUbwI7JeQpCdbO6PgYvrzDYKLIuI2yXtBqyUdB2wBLg+Ik6XdApwCvDpyYQ3M7Opa/QYwRll90eBtRGxbqIZIuIh4KF0/ylJdwELgKOAvjTZ+cAgLgRmZm2jiKg/FSCpxLaDxj+LiE0Nr0RaCNwMHAA8EBFzy8Y9HhHb7R6StBRYClAqlRYPDAw0urqWGxkZoaenp90xthpev7mh6UqzYOOW6VvvogVzpm9hNXRaWzeiGzNDd+bu1sz3b6595p6pvK/6+/tXRkRvvekaKgSS/gfwT2Tf3gX8GXByRKxoYN4e4CbgSxFxiaQnGikE5Xp7e2NoaKhuznYZHBykr6+v3TG2qnVx+UrLFo1y5nCjG4X1teLi9Z3W1o3oxszQnbm7NfOSa56uOX4q7ytJDRWCRj8F/hfwhrGtAEnzgP8DTFgIJO0M/AdwQURckgZvlDQ/Ih6SNB9oeMvCzMymX6O9hl5QsSvo0XrzShJwLnBXRJxVNuoKtp2y4kTg8gYzmJlZDhrdIrhG0k+AC9PjvwauqjPPm4ATgGFJq9KwzwCnAxdLej/wAPBXzUU2M7PpVO+axfsBpYg4WdJ/A95Mdozgp8AFE80bEbekaas5bBJZzcwsB/V2DZ0DPAUQEZdExCcj4hNkWwPn5B3OzMzyV68QLIyIOyoHRsQQ2WUrzcysy9UrBLtOMG7WdAYxM7P2qFcIfi7pg5UD04HelflEMjOzVqrXa+jjwKWSjmfbB38vMBM4Os9gZmbWGhMWgojYCLxRUj/Z6SEAfhwRN+SezMzMWqLR6xHcCNyYcxYzM2uDyV6PwMzMdhAuBGZmBedCYGZWcNN3DmIzM5tQtVPEL1s0Srs/ir1FYGZWcC4EZmYF50JgZlZwLgRmZgXng8XWVrWur9yK6x+bWcZbBGZmBZdbIZD0PUmbJN1ZNuxUSeslrUq3I/Nav5mZNSbPLYLzgCOqDD87Ig5Mt3rXPTYzs5zlVggi4mbgsbyWb2Zm00MRkd/CpYXAlRFxQHp8KrAEeBIYApZFxOM15l0KLAUolUqLBwYGcss5VSMjI/T09OS2/OH1m3NZbmkWbNwyfctbtGBO0/PU+t9qLSvvts5DN2aG7szd6Zmrvd7rvQ8n874a09/fvzIieutN1+pCUAIeAQL4AjA/It5Xbzm9vb0xNDSUW86pGhwcpK+vL7fl1+pZM1XLFo1y5vD0dRybTE+fZnsN5d3WeejGzNCduTs9c61TTEz0PpxKDzpJDRWClvYaioiNEfFcRDwPfAc4qJXrNzOz7bW0EEiaX/bwaODOWtOamVlr5PaDMkkXAn3AHpLWAZ8H+iQdSLZraA3wobzWb2ZmjcmtEETEcVUGn5vX+nYEeR0LMDObiH9ZbGZWcC4EZmYF50JgZlZwLgRmZgXn01BbS/hAuFnn8haBmVnBuRCYmRWcC4GZWcG5EJiZFZwLgZlZwbnXUI7cU8bMuoG3CMzMCs6FwMys4FwIzMwKzoXAzKzgfLDYpo0Pjpt1J28RmJkVXG6FQNL3JG2SdGfZsBdLuk7SPenvi/Jav5mZNSbPLYLzgCMqhp0CXB8R+wPXp8dmZtZGuRWCiLgZeKxi8FHA+en++cC78lq/mZk1RhGR38KlhcCVEXFAevxERMwtG/94RFTdPSRpKbAUoFQqLR4YGMgt51SNjIzQ09Oz3fDh9ZvbkKZxpVmwcUu7U1S3aMGcqsObbetay6llupZTrlbmTteNuTs9c7XXV7334VRee/39/SsjorfedB3baygilgPLAXp7e6Ovr6+9gSYwODhItXxLOrwXzbJFo5w53JkvgTXH91Ud3mxb11pOLdO1nHK1Mne6bszd6Zmrvb7qvQ+n8tprVKt7DW2UNB8g/d3U4vWbmVmFVheCK4AT0/0TgctbvH4zM6uQZ/fRC4GfAq+StE7S+4HTgcMl3QMcnh6bmVkb5baDOCKOqzHqsLzWaTuOWr9SPu+I2bku36yI/MtiM7OCcyEwMys4FwIzs4JzITAzK7jO/DVRlxlev7njfzxmVkTNdgpYc/rbc11+p/IWgZlZwbkQmJkVnAuBmVnBuRCYmRWcC4GZWcHt8L2Gah3Vb7Z3gHUG99CyPO0ovYCa5S0CM7OCcyEwMys4FwIzs4JzITAzK7gd/mDxdJnoINKyRS0MYk3ZkQ/+dUtHiFbkHFvHskWj7kwwCd4iMDMruLZsEUhaAzwFPAeMRkRvO3KYmVl7dw31R8QjbVy/mZnhXUNmZoWniGj9SqX7gceBAL4dEcurTLMUWApQKpUWDwwMTGpdw+s3NzX9ogVzml5OaRZs3NLUajpCN+ZuV+ZmXxfl04+MjNDT0zPtmRpZ91Rsemxz1bZudvmTydnsPGPT74iv6ak8n/39/Ssb2fXerkKwZ0RskPRS4DrgpIi4udb0vb29MTQ0NKl1TdeFKSbuNTTKmcPd1wGrG3O3K3Ozr4vy6QcHB+nr65v2THn3xvn6BZdXbevpunjLRMtpdp7yXkM72mt6Ks+npIYKQVt2DUXEhvR3E3ApcFA7cpiZWRsKgaTZknYbuw/8OXBnq3OYmVmmHdtQJeBSSWPr/7eIuKYNOczMjDYUgoi4D3htq9dr1krl+7in+mvX6drnn/cxhWaPx+3Iv/ruNu4+amZWcC4EZmYF50JgZlZwLgRmZgXXXb+8aAEfwLJO02kHYf0e2fF4i8DMrOBcCMzMCs6FwMys4FwIzMwKzgeLzRrgA6S2I/MWgZlZwbkQmJkVnAuBmVnBuRCYmRWcC4GZWcG515BZwdXqEbVsUYuDWNt4i8DMrODaUggkHSHp15LulXRKOzKYmVmmHRevnwH8M/A24NXAcZJe3eocZmaWaccWwUHAvRFxX0T8ARgAjmpDDjMzAxQRrV2hdAxwRER8ID0+AfjTiPhoxXRLgaXp4auAX7c0aHP2AB5pd4hJ6Mbcztw63ZjbmcfbJyLm1ZuoHb2GVGXYdtUoIpYDy/OPM3WShiKit905mtWNuZ25dboxtzNPTjt2Da0D9i57vBewoQ05zMyM9hSCnwP7S9pX0kzgWOCKNuQwMzPasGsoIkYlfRT4CTAD+F5ErG51jmnWFbuwqujG3M7cOt2Y25knoeUHi83MrLP4l8VmZgXnQmBmVnAuBE2QtEbSsKRVkoaqjJekr6VTZ9wh6fXtyFmRqV7mPkmb0/hVkv6hHTkrSZoraYWkuyXdJemQivGd2Nb1MndcW0t6VVmeVZKelPTximk6qq0bzNyJbf0JSasl3SnpQkm7VozfRdJFqZ1vk7SwZeEiwrcGb8AaYI8Jxh8JXE32W4mDgdu6IHMfcGW7c1bJdT7wgXR/JjC3C9q6XuaObOuyfDOAh8l+hNTRbd1A5o5qa2ABcD8wKz2+GFhSMc1HgG+l+8cCF7Uqn7cIptdRwPcjcyswV9L8dofqNpJ2B94CnAsQEX+IiCcqJuuotm4wc6c7DPhNRKytGN5RbV2hVuZOtBMwS9JOwAvZ/vdTR5F9mQBYARwmqdoPcKedC0FzArhW0sp0CoxKC4AHyx6vS8PaqV5mgEMk/VLS1ZJe08pwNbwC+C3wr5J+Iem7kmZXTNNpbd1IZui8ti53LHBhleGd1tblamWGDmrriFgPnAE8ADwEbI6Iaysm29rOETEKbAZe0op8LgTNeVNEvJ7szKl/J+ktFeMbOn1Gi9XLfDvZZvVrga8Dl7U6YBU7Aa8HvhkRrwOeBipPV95pbd1I5k5sawDSjzv/Evj3aqOrDGv367pe5o5qa0kvIvvGvy+wJzBb0rsrJ6sya0va2YWgCRGxIf3dBFxKdibVch13+ox6mSPiyYgYSfevAnaWtEfLg463DlgXEbelxyvIPmQrp+mktq6buUPbeszbgNsjYmOVcZ3W1mNqZu7Atn4rcH9E/DYingUuAd5YMc3Wdk67j+YAj7UinAtBgyTNlrTb2H3gz4E7Kya7AnhP6mVxMNnm30MtjrpVI5klvWxsP6Skg8heE4+2Omu5iHgYeFDSq9Kgw4BfVUzWUW3dSOZObOsyx1F7F0tHtXWZmpk7sK0fAA6W9MKU6zDgropprgBOTPePAW6IdOQ4b75mceNKwKXptbUT8G8RcY2kDwNExLeAq8h6WNwLPAO8t01ZxzSS+RjgbyWNAluAY1v14qvjJOCCtPl/H/DeDm9rqJ+5I9ta0guBw4EPlQ3r6LZuIHNHtXVE3CZpBdkuq1HgF8BySf8IDEXEFWQdDX4g6V6yLYFjW5XPp5gwMys47xoyMys4FwIzs4JzITAzKzgXAjOzgnMhMDMrOBcCM0DSoKS/qBj2cUn/MsE8I/knM8ufC4FZ5kK277c90XlszHYYLgRmmRXAOyTtApDOBb8nsErS9ZJuV3Zdh6MqZ0znvr+y7PE3JC1J9xdLuimd9O8nHXTWTrOtXAjMgIh4FPgZcEQadCxwEdmvUo9OJ+7rB85s9NTAknYmO+HZMRGxGPge8KXpzm42VT7FhNk2Y7uHLk9/30d2Rsgvp7O2Pk92quAS2cVQ6nkVcABwXaodM8hOQWzWUVwIzLa5DDhL2aUYZ0XE7WkXzzxgcUQ8K2kNsGvFfKOM37oeGy9gdUQcglkH864hsySdtniQbBfO2EHiOcCmVAT6gX2qzLoWeLWya87OITuzJMCvgXlK1y6WtHO7L5BiVo23CMzGu5DsXPFjPYguAH4kaQhYBdxdOUNEPCjpYuAO4B6yM0sSEX+QdAzwtVQgdgLOAVbn/l+YNcFnHzUzKzjvGjIzKzgXAjOzgnMhMDMrOBcCM7OCcyEwMys4FwIzs4JzITAzK7j/D/vpZJssXahGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# Generative Adversarial Networks (GAN) example in PyTorch. Tested with PyTorch 0.4.1, Python 3.6.7 (Nov 2018)\n",
    "# See related blog post at https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f#.sch4xgsa9\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "matplotlib_is_available = True\n",
    "try:\n",
    "  from matplotlib import pyplot as plt\n",
    "except ImportError:\n",
    "  print(\"Will skip plotting; matplotlib is not available.\")\n",
    "  matplotlib_is_available = False\n",
    "\n",
    "# Data params\n",
    "data_mean = 4\n",
    "data_stddev = 1.25\n",
    "\n",
    "# ### Uncomment only one of these to define what data is actually sent to the Discriminator\n",
    "#(name, preprocess, d_input_func) = (\"Raw data\", lambda data: data, lambda x: x)\n",
    "#(name, preprocess, d_input_func) = (\"Data and variances\", lambda data: decorate_with_diffs(data, 2.0), lambda x: x * 2)\n",
    "#(name, preprocess, d_input_func) = (\"Data and diffs\", lambda data: decorate_with_diffs(data, 1.0), lambda x: x * 2)\n",
    "(name, preprocess, d_input_func) = (\"Only 4 moments\", lambda data: get_moments(data), lambda x: 4)\n",
    "\n",
    "print(\"Using data [%s]\" % (name))\n",
    "\n",
    "# ##### DATA: Target data and generator input data\n",
    "\n",
    "def get_distribution_sampler(mu, sigma):#1xn data from a normal distribution\n",
    "    return lambda n: torch.Tensor(np.random.normal(mu, sigma, (1, n)))  # Gaussian\n",
    "\n",
    "def get_generator_input_sampler():\n",
    "    return lambda m, n: torch.rand(m, n)  # Uniform-dist data into generator, _NOT_ Gaussian(returns data of size mxn)\n",
    "\n",
    "# ##### MODELS: Generator model and discriminator model\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, f):\n",
    "        super(Generator, self).__init__()\n",
    "        self.m1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.m1(x)\n",
    "        x = self.f(x)\n",
    "        x = self.map2(x)\n",
    "        x = self.f(x)\n",
    "        x = self.map3(x)\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, f):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.f(self.map1(x))\n",
    "        x = self.f(self.map2(x))\n",
    "        return self.f(self.map3(x))\n",
    "\n",
    "def extract(v):\n",
    "    return v.data.storage().tolist()\n",
    "\n",
    "def stats(d):\n",
    "    return [np.mean(d), np.std(d)]\n",
    "\n",
    "def get_moments(d):\n",
    "    # Return the first 4 moments of the data provided (mean, std, skews, kurtoses)\n",
    "    mean = torch.mean(d)\n",
    "    diffs = d - mean\n",
    "    var = torch.mean(torch.pow(diffs, 2.0))\n",
    "    std = torch.pow(var, 0.5)\n",
    "    zscores = diffs / std\n",
    "    skews = torch.mean(torch.pow(zscores, 3.0))\n",
    "    kurtoses = torch.mean(torch.pow(zscores, 4.0)) - 3.0  # excess kurtosis, should be 0 for Gaussian\n",
    "    final = torch.cat((mean.reshape(1,), std.reshape(1,), skews.reshape(1,), kurtoses.reshape(1,)))\n",
    "    return final\n",
    "\n",
    "def decorate_with_diffs(data, exponent, remove_raw_data=False):\n",
    "    mean = torch.mean(data.data, 1, keepdim=True)\n",
    "    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[0][0])\n",
    "    diffs = torch.pow(data - Variable(mean_broadcast), exponent)\n",
    "    if remove_raw_data:\n",
    "        return torch.cat([diffs], 1)\n",
    "    else:\n",
    "        return torch.cat([data, diffs], 1)\n",
    "\n",
    "def train():\n",
    "    # Model parameters\n",
    "    g_input_size = 1      # Random noise dimension coming into generator, per output vector\n",
    "    g_hidden_size = 5     # Generator complexity\n",
    "    g_output_size = 1     # Size of generated output vector\n",
    "    d_input_size = 500    # Minibatch size - cardinality of distributions\n",
    "    d_hidden_size = 10    # Discriminator complexity\n",
    "    d_output_size = 1     # Single dimension for 'real' vs. 'fake' classification\n",
    "    minibatch_size = d_input_size\n",
    "\n",
    "    d_learning_rate = 1e-3\n",
    "    g_learning_rate = 1e-3\n",
    "    sgd_momentum = 0.9\n",
    "\n",
    "    num_epochs = 5000\n",
    "    print_interval = 100\n",
    "    d_steps = 20\n",
    "    g_steps = 20\n",
    "\n",
    "    dfe, dre, ge = 0, 0, 0\n",
    "    d_real_data, d_fake_data, g_fake_data = None, None, None\n",
    "\n",
    "    discriminator_activation_function = torch.sigmoid\n",
    "    generator_activation_function = torch.tanh\n",
    "\n",
    "    d_sampler = get_distribution_sampler(data_mean, data_stddev)#function to generate 1xn data from normal distribution\n",
    "    gi_sampler = get_generator_input_sampler()\n",
    "    G = Generator(input_size=g_input_size,\n",
    "                  hidden_size=g_hidden_size,\n",
    "                  output_size=g_output_size,\n",
    "                  f=generator_activation_function)\n",
    "    D = Discriminator(input_size=d_input_func(d_input_size),\n",
    "                      hidden_size=d_hidden_size,\n",
    "                      output_size=d_output_size,\n",
    "                      f=discriminator_activation_function)#input size=4 here\n",
    "    criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "    d_optimizer = optim.SGD(D.parameters(), lr=d_learning_rate, momentum=sgd_momentum)\n",
    "    g_optimizer = optim.SGD(G.parameters(), lr=g_learning_rate, momentum=sgd_momentum)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for d_index in range(d_steps):\n",
    "            # 1. Train D on real+fake\n",
    "            D.zero_grad()#set the gradients to 0 before applying backpropagation\n",
    "\n",
    "            #  1A: Train D on real\n",
    "            d_real_data = Variable(d_sampler(d_input_size))#generate d_input_size data from normal distribution\n",
    "            d_real_decision = D(preprocess(d_real_data))#get 4 moments of d_real_data##\n",
    "            d_real_error = criterion(d_real_decision, Variable(torch.ones([1,1])))  # ones = true, criterion is binary crosss entropy loss##\n",
    "            d_real_error.backward() # compute/store gradients, but don't change params\n",
    "\n",
    "            #  1B: Train D on fake\n",
    "            d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "            d_fake_data = G(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "            d_fake_decision = D(preprocess(d_fake_data.t()))\n",
    "            d_fake_error = criterion(d_fake_decision, Variable(torch.zeros([1,1])))  # zeros = fake\n",
    "            d_fake_error.backward()\n",
    "            d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
    "\n",
    "            dre, dfe = extract(d_real_error)[0], extract(d_fake_error)[0]\n",
    "\n",
    "        for g_index in range(g_steps):\n",
    "            # 2. Train G on D's response (but DO NOT train D on these labels)\n",
    "            G.zero_grad()\n",
    "\n",
    "            gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "            g_fake_data = G(gen_input)\n",
    "            dg_fake_decision = D(preprocess(g_fake_data.t()))\n",
    "            g_error = criterion(dg_fake_decision, Variable(torch.ones([1,1])))  # Train G to pretend it's genuine\n",
    "\n",
    "            g_error.backward()\n",
    "            g_optimizer.step()  # Only optimizes G's parameters\n",
    "            ge = extract(g_error)[0]\n",
    "\n",
    "        if epoch % print_interval == 0:\n",
    "            print(\"Epoch %s: D (%s real_err, %s fake_err) G (%s err); Real Dist (%s),  Fake Dist (%s) \" %\n",
    "                  (epoch, dre, dfe, ge, stats(extract(d_real_data)), stats(extract(d_fake_data))))\n",
    "\n",
    "    if matplotlib_is_available:\n",
    "        print(\"Plotting the generated distribution...\")\n",
    "        values = extract(g_fake_data)\n",
    "        print(\" Values: %s\" % (str(values)))\n",
    "        plt.hist(values, bins=50)\n",
    "        plt.xlabel('Value')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Histogram of Generated Distribution')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
